### 最终成果

1. 实用发明型专利
   1. 说明
   2. 图纸
2. 学术性 SCI
   1. 选择一个新颖的点切入研究
3. 应用型SCI
   1. 对应应用整个系统进行研究

### 下一届阶段的任务

#### 专利问题

需要确定的东西有

1. 光敏传感器?
2. 电气运动装置?可能是,气缸
3. 动作阈值可能在stm32中或者树莓派中进行设置
4. 电源供给问题
   产出有设计方案和图纸,应该是cad或者solidwork之类

#### 学术性sci

学术性的sci我们找一个切入点,最近非常热门的cv方向是,高精度三维重建`nerf`,3d-高斯方法,和三位的目标识别,三维的语义分割
我们找一个切入点是在高精度nerf或者高斯方法的模型下,进行空间的导航,地面和空间导航,适用于机器人领域,假设建图已经完成,
重点是研究,**高精度三位地图下的定位和空间导航**优化现有的算法,更贴近机器人的场景

#### 小车和应用型sci

##### 商家资料

1. 使用`gateway`或者`vscode`使用ssh连接小车，尝试根据官网给出的资料进行运行出实际效果，应付学校
   _意在熟悉，ros2，python，c++，ubuntu, shell,基本ide和解决错误的思维_

##### 应用型sci新方案

_尝试使用新方案前后端分离的方式_
大环境是，应用互联网的成熟，以及后端图形计算的成熟，以及现代的python高效的编码能力各种特性，实现一种现代化的

> 论文会与实际方案不太一致，论文更专注于后端（使用数据集更方便），应该是后端通用型方案，不局限于小车，也可能是无人机，机器人，假设仅仅根据前端的RGP图像给出运动策略，运动策略不需要表现为具体的运动指令，重点在于RGP->运动策略

对于实际的小车，可能会需要研究这些部分，其实大致和这张图是一样的
![../../../assets/Pasted_image_20240228171953.png](../../../assets/Pasted_image_20240228171953.png)
你需要设计好前端的客户端`client`，控制器`controller`，采集者`collector`,顾名思义，

1. 客户端大概率是python客户端，使用，**`websockets`这种异步通讯实时双向通讯框架和后端建立图像和指令流的实时框架**，前端也就两个数据流吧，**图像流**，**指令流**

   > 图像流是opencv很好读取的,因此你也要对python的opencv接口要熟悉
   > 指令流需要根据如何使用ros控制小车运动,指定一个`控制流数据类`,前后端要一致

2. 后端为了保持异步的高性能,以及和深度学习环境结合起来,仍然是选择主要为python,现代化的高性能的的网络框架 **`fastapi`**,这是深度模型或者后端机器学习应用首选的异步网络框架

   > 你可能得对python的异步语法熟悉,和网络框架

3. 前后端的接口部分,也就是python的client和后端的fastapi接口部分,使用现代化的`pydantic` 模型构建通讯接口标准的数据类,它可以运行时检查类型从而保证数据一致性
4. 对于相机数据的处理,得实际看深度相机的效果如何,如果深度相机不好,转换为使用[GitHub - SupaVision/Depth-Anything: Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data. Foundation Model for Monocular Depth Estimation](https://github.com/SupaVision/Depth-Anything)进行直接RPG转深度图像,两者选一种

5. 建图和定位使用经典的算法进行,现有的 比如`open3d`的点云处理,已经根据点云对齐已经是能够的进行实时三维重建和进行全局定位什么的,这个需要调整**组合经典算法**,因为图像数据量不大,以及后端性能很强,从现代化的这个点尝试去应用现有算法实现slam
6. 实现建图和定位之后,对于导航,可以根据现有的三位点云,进行导航,或者对于三位点云进行降维成**占用网格概率图**,转化成二维,使用经典导航算法

7. 对于运动指令的输出,需要根据前端的ros进行配套好,不出意外还是数据类

> 应用型sci,应该在后端应用成功的方法上做文章
