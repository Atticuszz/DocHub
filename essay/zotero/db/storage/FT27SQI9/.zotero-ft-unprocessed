{"indexedPages":8,"totalPages":8,"version":"55","text":"4078\n\nIEEE ROBOTICS AND AUTOMATION LETTERS, VOL. 5, NO. 3, JULY 2020\n\nPointNetKL: Deep Inference for GICP Covariance Estimation in Bathymetric SLAM\nIgnacio Torroba, Christopher Iliffe Sprague , Nils Bore , and John Folkesson\n\nAbstract—Registration methods for point clouds have become a key component of many SLAM systems on autonomous vehicles. However, an accurate estimate of the uncertainty of such registration is a key requirement to a consistent fusion of this kind of measurements in a SLAM ﬁlter. This estimate, which is normally given as a covariance in the transformation computed between point cloud reference frames, has been modelled following different approaches, among which the most accurate is considered to be the Monte Carlo method. However, a Monte Carlo approximation is cumbersome to use inside a time-critical application such as online SLAM. Efforts have been made to estimate this covariance via machine learning using carefully designed features to abstract the raw point clouds [1]. However, the performance of this approach is sensitive to the features chosen. We argue that it is possible to learn the features along with the covariance by working with the raw data and thus we propose a new approach based on PointNet [2]. In this work, we train this network using the KL divergence between the learned uncertainty distribution and one computed by the Monte Carlo method as the loss. We test the performance of the general model presented applying it to our target use-case of SLAM with an autonomous underwater vehicle (AUV) restricted to the 2-dimensional registration of 3D bathymetric point clouds.\nIndex Terms—SLAM, novel deep learning methods, marine robotics, simultaneous localization and mapping, robot learning, unmanned underwater vehicles.\nI. INTRODUCTION\nO VER the last few years, sensors capable of providing dense representations of 3D environments as raw data, such as RGB-D cameras, LiDAR or multibeam sonar, have become popular in the SLAM community. These sensors provide accurate models of the geometry of a scene in the form of sets of points, which allows for a dense representation of maps easy to visualise and render. The wide use of these sensors has given rise to the need for point cloud registration algorithms in the robotics and computer vision ﬁelds. For instance, the core of well-established SLAM frameworks for ground and underwater robots, such as [3] and [4], relies upon point cloud registration methods, such as the iterative closest point (ICP) [5], to provide measurement updates from dense 3D raw input.\nManuscript received December 9, 2019; accepted March 25, 2020. Date of publication April 20, 2020; date of current version May 6, 2020. This letter was recommended for publication by Associate Editor Prof. Giorgio Grisetti and Editor Prof. Sven Behnke upon evaluation of the reviewers’ comments. (I. Torroba and C. I. Sprague contributed equally to this work.) (Corresponding author: Christopher Iliffe Sprague.)\nThe authors are with the Swedish Maritime Robotics Centre (SMaRC) and the Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, SE-100 44 Stockholm, Sweden (e-mail: torroba@kth.se; sprague@kth.se; nbore@kth.se; johnf@kth.se).\nDigital Object Identiﬁer 10.1109/LRA.2020.2988180\n\nWhile well rooted in indoor and outdoor robotics, SLAM has\n\nnot yet gained widespread use for AUVs. However, the need for\n\nSLAM is greater underwater, as navigation is extremely chal-\n\nlenging. Over long distances, sonar is the only viable sensor to\n\ncorrect dead-reckoning estimates. Of the various types of sonar,\n\nmultibeam echo sounders (MBES) provide the most suitable\n\ntype of raw data for SLAM methods. This data is essentially a\n\npoint cloud sampled from the bathymetric surface, and applying\n\nregistration methods to these measurements is a well-studied\n\nproblem [6]. However, when fusing the output of the registration\n\ninto the Bayesian estimate of the AUV state, the uncertainty of\n\nthe transform must be modelled, since it represents the weight\n\nof the measurement. Despite its importance in every SLAM\n\ndomain, few works have addressed the problem of estimating\n\nthis uncertainty accurately and efﬁciently, usually in the form of\n\na covariance matrix. We argue that these two requirements are\n\nvital in our setting and need to be addressed simultaneously and\n\nonboard an AUV, with limited computational resources. While\n\nthere have been recent attempts to derive the covariance of the\n\nregistration process analytically, these approaches were limited\n\neither by the reliability of the estimation or its complexity. The\n\nlatest and most successful techniques, however, have aimed at\n\nlearning such a model. [1] is an example of this approach applied\n\nto constraints created from point clouds registrations with ICP.\n\nHowever, although successful, it is limited by the need to reduce\n\nthe input point clouds to hand-crafted feature descriptors, whose\n\ndesign can be a non-trivial, task-dependent challenge. Hence, we\n\nmotivate our work with the goal to circumvent the need to design\n\nsuch descriptors, and to instead learn the features directly from\n\nthe underlying raw data. We accomplish this with the use of the\n\nrelatively recent artiﬁcial neural network (ANN) architecture,\n\nPointNet [2]. We combine PointNet and a parameterisation of\n\na Cholesky decomposition of the covariance of the objective\n\nfunction into a single model, named PointNetKL, which is\n\ninvariant to permutations of its input. In this work, we use this\n\narchitecture to estimate the Generalised-ICP (GICP) [7] uncer-\n\ntainty distributions directly from raw data and test the learned\n\nmodel in a real underwater SLAM scenario. Our contributions\n\narerlisWteedparsesfoenlltoPwosi:ntNetKL, a new learning architecture built\n\nupon PointNet, for learning multivariate probability distri-\n\nr\n\nbutions from unordered sets of V -dimensional points. We apply this general architecture to the restricted case of\n\nlearning 2D covariances from the constrained GICP reg-\n\nistration of real 3D bathymetric point clouds from several\n\nunderwater environments.\n\nThis work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\n\nTORROBA et al.: PointNetKL: DEEP INFERENCE FOR GICP COVARIANCE ESTIMATION IN BATHYMETRIC SLAM\n\n4079\n\nr We assess the performance and generalisation of our archi- section, we revisit the most relevant of these methods and the\n\ntecture in both the regression and SLAM tasks.\n\nprevious work upon which our approach builds.\n\nII. FORMAL MOTIVATION\nA point cloud registration algorithm can be deﬁned as an optimisation problem aimed at minimising the distance between corresponding points from two partially overlapping sets of points, Si and Sj, with rigidly attached reference frames Ti and Tj. In the general case, a point cloud Pi = {Si, Ti} consists of an unordered set of V -dimensional points Si while a reference frame Ti ∈ SE(3) represents a 6-DOF pose. According to this, an unbiased registration process can be modelled as a function h of the form\n\nTij = Ti−1Tj = h(Pi, Pj ),\n\n(1)\n\nwhere h(Pi, Pj) is the true relative rigid transformation between the two frames. This transformation is estimated to minimise the\nalignment error to Sj when applied to Si. However, it is well known that due to the fact that point cloud registration locally\noptimises over a non-convex function, its solution is sensitive to\nconvergence towards local minima and so its performance relies\ncrucially on the initial relative transformation between the point clouds, computed as Tˆi−1Tˆj. Where the hat denotes the current best estimate of the pose.\nThe uncertainty in the estimate of the true transformation can\nbe represented within a SLAM framework as follows. Given\nan autonomous mobile robot whose state over time is given by xi ∈ RN and with a dead reckoning (DR) system that follows a transition equation 2, we can model a measurement update based on point cloud registration through Eq. 3, where zij ∈ RM with M ≤ N.\n\nxi = g(xi−1, ui) + i\n\n(2)\n\nzij = h(Pi, Pj ) + δij .\n\n(3)\n\ni and δij model the error in the DR and in the registration\nrespectively. Approximating the noise in the DR and measurement models as white Gaussian with covariances R ∈ RN×N and Q ∈ RM×M , respectively, both xi and zij will follow prob-\nability distributions given by\n\nxi ∼ N (g(xi−1, ui), Ri)\n\n(4)\n\nzij ∼ N (h(Pi, Pj ), Qij )\n\n(5)\n\nWith zij being measurements of the transform between point clouds from the registration algorithm and the true transform h(Pi, Pj) being given by the Ti and Tj. The Bayesian estimate that results from this model is generally analytically intractable\ndue to the nonlinear terms, but iterative maximum likelihood\nestimates (MLE) are possible. Such an iterative SLAM estimate\nrequires a reliable approximation of the probability distribution of the registration error δij ∼ N (0, Qij). This is because Q−ij1 represents the weight or “certainty” of the measurement zij when being added to the state estimate, which is a critical step in\nany state-of-the-art SLAM solution. However, this covariance\nis not available and research has focused on deriving both\nanalytical and data-driven methods to estimate it. Over the next\n\nIII. RELATED WORK\nAs introduced above, the need of SLAM systems for a reliable approximation of the error distribution of point cloud registration processes has motivated a proliﬁc body of work in this topic. Among the numerous existing registration techniques, the ICP algorithm and its variants, such as GICP, are the most widely used in the SLAM community. The methods to estimate the uncertainty of the solution of ICP-based techniques are traditionally divided into two categories: analytic and data-driven. Analytical solutions based on the Hessian of the objective function, such as [8], have yielded successful results on the 2D case thanks to its capacity to model the sensor noise. However, [9] shows that its extension to 3D contexts results in overly optimistic results, which do not reﬂect the original distribution. Another set of approaches, such as [10], consists in developing estimation models for speciﬁc sensors. Although more accurate, this kind of method suffers in its inability to generalise to different sensors.\nThere is a large body of work on non-parametric approaches to estimating probability distributions, e.g. [1], [11], [12]. In [11], Iversen et al. apply a Monte-Carlo (MC) approach to estimate the value of the covariance of ICP on synthetic depth images. Although accurate, this approach cannot be applied online due to its computation time. In [12], a general non-parametric noise model was proposed; however, its performance is adversely affected by scaling with higher-dimensional features. Landry et al. introduce, in [1], the use of the CELLO architecture for ICP covariance estimation. This method proves to be a reliable estimation framework but it is limited by the need to create hand-crafted features from the raw 3D point clouds. As argued in [13], designing these features for a given task is still an open issue and so the success of CELLO is highly dependant on the chosen features.\nGoing beyond hand-crafted features, a number of works have addressed the problem of learning feature representations from unordered sets such as point clouds; however, these approaches do not capture spatial structure. As a result, there have been a number of point cloud representations developed through multi-view [14] and volumetric approaches [15]. Unfortunately, multi-view representations are not amenable to open-scene understanding, and volumetric representations are limited by data resolution and the computational cost of convolution.\nThe work in [16] presents an inference framework based on a deep ANN, DICE, that can be trained on raw images. This work, to the best of our knowledge, represents the ﬁrst instance of the use of a ANN to infer the uncertainty of a measurement model in a similar approach to ours. However, their network is limited to camera input and they require ground truth measurements to construct the training set, a commodity often hard to afford.\nTo counteract the need to preprocess the input point clouds as in [1] while being able to apply deep learning techniques as in [16], we have turned to the seminal work PointNet [2] for our method. When choosing between learning architectures, e.g. [17], [18], we choose PointNet for its simplicity. This being the\n\n4080\n\nIEEE ROBOTICS AND AUTOMATION LETTERS, VOL. 5, NO. 3, JULY 2020\n\nﬁrst use of ANNs for bathymetric GICP covariance estimation, our results can serve as a ﬁrst baseline.\nPointNet employs a relatively simple ANN architecture, that achieves striking performance in both classiﬁcation and segmentation tasks upon raw point cloud data. It relies on the principle of composing an input-invariant function through the composition of symmetric functions, producing an inputinvariant feature vector for a given point cloud.\nWhile the PointNet architecture was originally intended for classiﬁcation and segmentation, the internally generated feature vectors have been used for other purposes, such as point cloud registration [19] and computation of point cloud saliency maps [20]. Similarly to these works, we seek to employ PointNet for a different purpose, namely for the estimation of multivariate probability distributions.\n\nIV. APPROACH\nOur goal is to estimate, for each pair of overlapping bathymetric point clouds Pi, Pj, a covariance Qij that is as close as possible to modelling the actual uncertainty of their GICP registration in underwater SLAM, given by δij ∼ N (0, Qij). Learning these covariances entails the use of datasets with large amounts of overlapping point clouds with accurate associated positions, such as the one used in [1]. However, an equivalent dataset does not exist in the underwater robotics literature, due to the nature of bathymetric surveys with a MBES pointing downwards, where the consecutive MBES pings within swaths do not contain overlap.\nIn order to overcome this problem, we look into sources of uncertainty in the registration of bathymetric point clouds. In general Qij is a function of the amount of sensor noise, the statistics over the initial starting point for the iterative MLE, and the features in the overlapping sections of the two point clouds. If we assume that Si has uniform terrain characteristics, i.e. there is not a small rocky corner on an otherwise ﬂat point cloud, we can expect that Qi does not vary much with the speciﬁc region of overlap as long as that region is above a certain percentage of the whole point cloud. This allows us to attribute an intrinsic covariance to each point cloud independent of the actual overlap, i.e. Qij becomes Qi (which is also approximately Qj). The validity of this is based on the fact that it is possible to aggregate raw sonar data on fairly uniform point clouds with the submaps approach used in [21], for example.\n\nA. Learning Architecture\nIn this section we present a general approach to the problem of learning our target GICP covariance Qi from a set of points Si. Formally, we consider the problem of learning a function πθ(Si), parameterised by a set of learnable parameters θ, that maps a point cloud of U points Pi = {Si ∈ RU×V , Ti ∈ RM } to a multivariate Gaussian probability distribution N (μi, Σi) : μi ∈ RM , Σi ∈ RM×M , where Σi is strictly positive-deﬁnite. We solve this problem by optimising πθ’s parameters θ to regress a dataset of the form\n\nD = {(S0, μ0, Σ0) , . . . , (SK , μK , ΣK )} ,\n\n(6)\n\nFig. 1. Depiction of the architecture of PointNetKL. From left to right: a submap is fed into PointNetKL to produce a global feature vector that is then fed into a multilayer perceptron to produce the parameters of a Cholesky decomposition and construct a positive-deﬁnite covariance matrix.\n\nconsisting of K point clouds and their associated distributions.\nTo tackle this problem we consider the PointNet architecture\n[2] in order to work directly with the raw point clouds. We denote PointNet as function φ(Si) : RU×V → RZ that maps Si to a Z-dimensional vector-descriptor ζi ∈ RZ, describing the features of Si. Using ζi we seek to learn a further mapping to the distribution N (μi, Σi). Given the invariance of ζi, we postulate that the further abstraction to deﬁning a probability distribution\ncan be achieved by a simple MLP, denoted hereafter as ψ(ζi). In order to deﬁne our target distribution δi, we task ψ to output\na covariance matrix Σi = Qi and set μi equal to the null vector. We describe this model collectively as\n\nπθ(Si) = ψ (φ (Si)) : RU×V → RM×M ,\n\n(7)\n\nwhere θ is the collective set of learnable parameters. Hereafter, we denote πθ as π for brevity.\nWe leave the architecture of φ as originally described in [2], removing the segmentation and classiﬁcation modules. For the hidden model of ψ we consider a fully connected feed-forward architecture of arbitrarily many layers and nodes per layer. For each layer we sequentially apply the following standard machine learning operations: linear transformation, 1D batch normalisation, dropout, and rectiﬁed linear units, as indicated in Fig. 1. This characterisation of ψ produces outputs in R≥0, which are transformed into desired ranges in the following section.\n\nB. Covariance Matrix Composition\nIn order to map the outputs of ψ to a valid estimation of Σi we must enforce positive-deﬁniteness. Following [16], we task ψ to produce the (M 2 − M )/2 + M parameters of a Cholesky composition of the form\nΣi = L(li)D(di)L(li) : li ∈ R(M2−M)/2, di ∈ RM >0, (8)\nwhere L(li) is a lower unitriangular matrix, D(di) is a diagonal matrix with strictly positive values, and [li, di] are the parameters to be produced by ψ. It is important to note that the strict positiveness of D(di)’s elements enforces the uniqueness of the decomposition and thus that of the probability distribution being estimated. Using a linear transformation layer, we map the penultimate outputs of ψ to (M 2 − M )/2 + M values describing the elements of li and di. To enforce the positivity of di, we simply apply the exponential function such that the\n\nTORROBA et al.: PointNetKL: DEEP INFERENCE FOR GICP COVARIANCE ESTIMATION IN BATHYMETRIC SLAM\n\n4081\n\nFig. 2. 500 × 40 meters (approx.) sample of a swath of bathymetry from the Baltic dataset.\n\ndecomposition becomes Σi = L(li)D(exp(di))L(li) . We then use Σi to fully characterise δi.\n\nC. Loss Function\n\nTo train π, we must compare its predicted distributions with the true ones in order to compute its loss. For this purpose we use the Kullback-Leibler (KL) divergence\n\nDKL (N ||Nπ)\n\n=\n\n1 2\n\ntr Σ−π1Σ\n\n+ (μπ − μ)\n\nΣ−π 1\n\n× (μπ − μ) − M + ln\n\ndet(Σπ ) det(Σ)\n\n, (9)\n\nwhere tr(·) and det(·) are the trace and determinant matrix operations, respectively. This gives us the distance between the distribution N (μπ, Σπ) predicted by π and the target distribution N (μ, Σ). We optimise π to minimise DKL, hence we coin its name, PointNetKL. As explained in IV-A, in our speciﬁc application μ = 0 and so the variable μ will be omitted for\nbrevity from here on.\n\nD. Generation of Training Data\n\nThe datasets necessary to train, test and validate our ANN\nhave been generated following an approach similar to [11]. A\nMonte Carlo approximation has been computed for every point cloud Si as follows. Given a 3D point cloud Pi = {Si, Ti} and a distribution O ∼ N (0, Σsample), we generate a second point cloud Pj by perturbing Pi with a relative rigid transform Tj drawn from O. After the perturbation, Gaussian noise is applied\nto Sj and the resulting point clouds are registered using GICP. Given the fact that Pj is a perturbation of Pi, the error of the GICP registration can be computed as the distance between the obtained transformation Tˆj and the perturbation originally applied Tj, as in Eq. 10, [22]. This error is then used to calculate the covariance of the distribution δi for each point cloud following Eq. 11.\n\nel = log(exp(Tˆj)−1Tj)\n\n(10)\n\nQi\n\n=\n\n(L\n\n1 − 1)\n\nL\n\neleTl\n\n(11)\n\nl=1\n\nwhere L is the total number of MC iterations per point cloud.\n\nV. EXPERIMENTS\nIn the remainder of this paper we apply the presented general approach for learning Gaussian distributions from unordered sets of points to the speciﬁc problem of bathymetric graph SLAM with GICP registration as introduced in [21]. The reason to focus on GICP as opposed to ICP is that this method works\n\nFig. 3. Depiction of the zero-meaned, normalised, and voxelised submaps of two datasets. The dispersion of the points around the unit sphere indicate diversity of the bathymetry.\nbetter on the kind of bathymetric point clouds produced from surveys of unstructured seabed, as discussed in [6].\nThe nomenclature used this far can be instantiated to this speciﬁc context as follows. A point cloud Pi consists now of a bathymetric submap in the form of a point cloud Si ∈ RU×3 and the estimates of the AUV pose while collecting the submap are Ti = exp(xi) ∈ R6. In the case of the GICP registration, the vehicles used to collect the data provided a good direct measurement of the full orientation of the platform and the depth underwater. Due to this, the dimension of the measurement model zi in Eq. 12 has been reduced to m = 2, since it is only the x and y coordinates that contain uncertainty. Consequently, the GICP registration is constrained during the training data generation to the dimensions x, y and therefore the covariances of δi and of the prior O become R2 matrices.\nA. The Training Datasets\nTo the best of our knowledge, no dataset like the one in Eq. 6 with bathymetric submaps exists and therefore a new one has been created. When designing such a dataset several criteria must be fulﬁlled for the training to be successful and having generalisation of the results in mind: i) The success of GICP will be, to a certain degree, linked to the features in the submap being registered. In simple cases this can be easily interpreted by looking at the resulting covariance. Intuitively, on a perfectly ﬂat submap, an elongated feature along the y direction will ease the registration perpendicular to that axis, yielding low values of the covariance for the x axis. Equivalently, the registration along y will result in a bigger uncertainty since the submaps can slide along the feature. Thus, given that π is learning a mapping from geometric features to covariance values, it is important that the dataset created contains enough variation in the bathymetry. ii) It is not possible to collect and train on enough data for π to be able to generalise successfully to the whole sea ﬂoor worldwide. However, [23] proved that pieces of seabed can be successfully modelled through Gaussian processes. Based on this it can be assumed that with a large and varied enough dataset, our model should be able to generalise to natural seabed environments never seen before. This would help to circumvent the fact that this kind of data is very scarce and difﬁcult to obtain in comparison to image or point cloud datasets. iii) Different\n\n4082\n\nTABLE I DATASETS CHARACTERISTICS\n\nIEEE ROBOTICS AND AUTOMATION LETTERS, VOL. 5, NO. 3, JULY 2020\n\nvehicles are used to collect the data as to ease generalisation. iv) Ground truth (GT) is not available.\nIn order to ensure a complete distribution of geometric features within the dataset, we have analysed the spatial distribution of the points within the dataset used, with special attention to the dispersion in the z axis, given by the standard deviation σz. Fig. 3 shows a canonical representation of the zero-meaned, normalised, and voxelized submaps for two of the datasets used, whose characteristics are given in Table I.\nWith the view on the criteria exposed above, four bathymetric surveys have been included in the ﬁnal dataset. They have been collected in four different environments, namely: the south-east Baltic sea, the Shetland Isles, Gullmarsfjorden near Bornö, and underneath the Thwaites glacier in Antarctica. A sample of bathymetry from the Baltic dataset can be seen in Fig. 2. For the data collection, two state-of-the-art vehicles have been used. A remotely operated vehicle (ROV) Surveyor Interceptor and a Kongsberg Hugin AUV with an acoustic beacon Kongsberg cNode Maxiboth deployed in the survey area. Both vehicles were equipped with a MBES EM2040. With these four bathymetric surveys, the training datasets of the form given in Eq. 6 have been generated as explained in IV-D, with K = 9080 submaps and L = 3000 MC iterations per submap. Following the reasoning in [1], we have set Σsample = aI (where I ∈ R2) with a = 9 in order to model a reasonable underwater SLAM scenario.\n\nFig. 4. Evolution of π’s KL divergence loss on the training and validation sets. Note the unity of the training and validation curves over episodes, indicating generalisation. The jaggedness of the lines is a result of the stochasticity of the gradient descent, due to random subset sampling and dropout.\nThe implemented training hyperparameters are: 1) learning rate = 1 × 10−4, 2) L2 weight decay penalty = 1 × 10−4, 3) dropout probability = 40%, 4) batch size = 500, 5) validation set proportion = 20%, 6) early stopping patience1 = 20. Before the submaps are fed to network, they need to be pre-processed. Each set Si is translated to be zero-mean, then normalised to a sphere by the largest magnitude point therein, and ﬁnally voxelised to obtain a uniform density grid sampling. This ensures that the raw density of each set Si does not affect the underlying relation that π seeks to learn. Note, we use voxelisation here merely as a means to downsample the point clouds to lessen memory requirements. In principle, any downsampling method (not necessarily ordered) or none at all could be used.\n\nB. Training Implementation\nIn this work, we leave the internal architecture of PointNet φ as it is in [2], outputting the vector-descriptor ζ ∈ R1024. For the MLP, mapping ζ to the estimation of GICP covariance Q, we consider an architecture of 4 hidden layers, each having 1000 nodes, using the sequential operations described at the end of Section IV-A. A depiction of the ﬁnal ANN can be seen in Fig. 1.\nTo learn the mapping of submaps Si to covariances Qi, we optimise the parameters of π to regress the dataset D under the cost function DKL given in Eq. (9). We optimise these parameters with stochastic gradient descent (SGD), using the AMSGrad variant of the adaptive optimiser, Adam [24]. In order to improve the generalisation of π to different environments, we employ dropout [25] and weight decay [26].\nFor each training episode we sample a random subset (with replacement) of both the training and validation datasets, using the former for an optimisation iteration and the latter to evaluate the generalisation error in order to employ early-stopping [27]. We employ random subset sampling in conjunction with SGD in order to speed up training, as obtaining a gradient over the whole dataset described in Table I is intractable.\n\nC. Testing of the Covariances in Underwater SLAM\n\nThe validity of the covariances predicted by the network has been tested in the PoseSLAM framework in Eq. 12.\n\nNDR\n\n{x∗i } = arg min\nxˆ\n\ni\n\n||g(xˆi−1, ui) − xˆi||2Ri\n\nNLC\n\n+\n\n||Tˆ−1(xˆi)T (xˆj ) − zij ||2Qi\n\n(12)\n\n{i,j}\n\nWhere NDR and NLC are the number of dead reckoning and loop closure (LC) constraints, respectively. Qi models the weight of each LC edge added to the graph as a result of a successful GICP registration of overlapping submaps Pi, Pj and as such it plays an important role in the optimisation.\nFor the tests, two underwater surveys outside the training dataset of the network have been used, named Bornö 8 and Thwaites 11. For the test on each scenario, a bathymetric pose graph is created and optimised similarly to [21]. The graph optimisations have been run with three different sets of covariances:\n\n1Number of iterations to wait after last validation loss improved.\n\nTORROBA et al.: PointNetKL: DEEP INFERENCE FOR GICP COVARIANCE ESTIMATION IN BATHYMETRIC SLAM\n\n4083\n\nFig. 5. Left to right: Bornö 8 and Thwaites 11 surveys. Example of corrupted graph for the later (RM SExyz 301.1 m) and its MC solution (RM SExyz 222.18 m).\nTABLE II KL DIVERGENCE LOSS OF POINTNETKL π ON THE TRAINING AND\nVALIDATION AND TESTING SETS\n\nTABLE III AVERAGE RUNTIME OF THE GENERATION METHODS\n\nthose obtained with our method, the ones approximated with\n\nMC method and a constant covariance for each experiment. The\n\nresults of the optimisation processes have then been compared\n\nbased on two different error metrics, RM SExyz, [28] and the\n\nmarp-tRo-MmaSpEmxyeztr:imc pearosuproessedthiene[r2ro9r]:in reconstructing the AUV\n\nr\n\ntrajectory. The map-to-map error: measures the geometric consistency\n\nof the ﬁnal map on overlapping regions.\n\nThe aim of these tests is to assess the inﬂuence of the GICP\n\ncovariances on the quality of the PoseSLAM solution. To this\n\nend, two modiﬁcations have been introduced in the construction\n\nof the pose graph with respect to [21]:\n\n1) The submaps created are all of roughly the same length.\n\n2) The initial map and vehicle trajectory are optimised in our\n\ngraph SLAM framework using an estimate of the real R\n\nfrom the vehicle and the MC estimated covariances for Q\n\nin Eq. (12) and used in lieu of actual ground truth, ‘GT’.\n\nThis second point can be further motivated by: i) the relatively\n\nhigh quality of the survey together with the absence of actual\n\nGT; ii) we will be disrupting the vehicle trajectory by adding\n\nGaussian noise much greater than the navigation errors. Thus\n\ncomparing the different optimisation outputs with respect to\n\nthe undisrupted optimised estimate gives a valid comparison\n\nof methods as long as estimates are sufﬁciently further from\n\nthe navigation than we believe the navigation is from the actual\n\nground truth. More to the point we do not intend to prove that the MC method leads to a consistent estimate, for that we refer to the [11]. Instead we wish to show that we can approximate well the solution that the MC method gives with our method.\nC. Appendix B\nAlgorithm 1 outlines the process followed to create the graphs for the optimisation tests. As input it requires a ‘GT’ dataset, which we approximate optimising the navigation estimate from the vehicle DR as in [21] using the MC covariances computed. Given the estimated GT dataset divided into a set of N submaps SN , a graph G is constructed in lines 2 to 12. The initial bathymetry map from the undisrupted data can be seen in Figs. 5a and 5b. In line 14 the output graph is corrupted with additive Gaussian noise with covariance Rc. An instance of the resulting bathymetry and graphs are shown in Figs. 5c and 5d respectively. The arrows among consecutive submaps represent DR edges, while the non-consecutive ones depict the LC constraints. The noise has been added to the graph once built instead of to the navigation data to ensure that the loop closure detections are preserved disregarding of the noise factor used. However, an extra step must be taken to ensure a registration consistent with the assumptions on GICP initialisation as in Section IV-D. In the\n\n4084\n\nIEEE ROBOTICS AND AUTOMATION LETTERS, VOL. 5, NO. 3, JULY 2020\n\nTABLE IV GRAPH-SLAM RESULTS FOR THE FOUR SETS OF COVARIANCES USED IN THE OPTIMISATION OF THE TWO ‘CORRUPTED’ DATASETS. OBSERVE HOW ‘OUR’\nMETHOD APPROXIMATES WELL THE ‘MC’ RESULT FOR THWAITES 11 AND EVEN OUTPERFORMS IT FOR BORNÖ 8\n\ncase of a loop detection, the target submap Si is perturbed with a transformation drawn from O before being registered against the fused submaps in SLC . That is we assume that there is, along with a good loop closure detection, an estimated starting point for GICP as given by the distribution O. The coverage variable determines how much overlap must exist between two submaps for it to be considered a loop closure. It has been set to 60% of Si.\nVI. RESULTS\nA. Assessment of the NN Predictions\nWe assess the performance of π on the training, validation, and testing sets with the KL divergence loss described in Section IV-C. In Fig. 4, the training and validation loss maintain a strong coherence, indicating a good generalisation performance. As indicated in Table II, π not only converges to low training and validation values, it also generalises well to the unseen testing sets. Understandably, the network performs quite well in the Bornö 8 validation set, in comparison to Thwaites 11, because the former is rather homogeneous in terms of feature types, whereas the latter includes many severe features on a larger scale.\n\nduring the mission, but is sensitive to the noise and sparsity of the point clouds. For the second method, “Constant Q” as in [16], all LC edges have the same Qi, which in our case is computed a posteriori by averaging the MC solutions of all the submaps.\nWhen looking at the Thwaites 11 results, considering the ‘MC’ method as the gold standard, it can be seen that it yields the smallest RM SExyz error, as expected. Our method outputs a slightly worse RM SExyz and similar Map-to-map error to MC and is signiﬁcantly better than the two baseline approaches. However, in the Bornö 8 dataset our method’s RM SExyz error is better than the ‘MC’ output and very similar to the ‘Naïve GICP’. This might be explained by the bathymetric data itself. The submaps from Bornö contain far fewer features than those from Thwaites, and usually on the edges. This makes the submap’s terrain less homogeneous, violating our assumption on Section IV. It is possible that the network had difﬁculty learning these non-homogeneous cases and tended to treat mostly ﬂat submaps more like completely ﬂat. Then in the actual estimation, where the feature parts may not overlap at all, this resulted in a better output of the optimisation. The covariances from the ‘Naïve GICP’ are generally ﬂat for large, noisy bathymetric point clouds. This explains why they have performed so well in this dataset and so poorly in Thwaites 11, which contains more features.\n\nB. SLAM Results\nThe assessment of the covariances on an underwater SLAM context has been carried out on the two subsets from the Antarctica and Bornö datasets in Fig. 5. The results from the optimisation of the graphs generated from Algorithm 1 can be seen in Table IV. They have been averaged over 100 repetitions where noise was added to the ‘GT’, which was then optimised. The RM SExyz error under ‘Navigation’ indicates the correction from the DR estimate of the navigation after optimising it. The resulting trajectory and bathymetry have been then corrupted with Gaussian noise parameterized by a covariance Rc6x6 whose only non-null component is Rc(5, 5) = 0, 01, modelling the noise added to the yaw of the vehicle. The average errors from the corrupted graphs are given on the column “Corrupted”. The next four columns contain the ﬁnal errors after the optimisations carried out with the covariances generated with the different methods tested. Our method has been compared against the covariances generated from the MC approximation in Section IV-D and against two baseline approaches. A vanilla method consisting on approximating the information matrix of GICP, so called here “Naïve GICP”, using the average of the information matrix in Eq. 2 in the original paper [7], projected onto the xy plane for the current experiments. This approximation doesn’t require any extra computation and can be run\n\nC. Runtime Comparison\nThe execution times of ‘MC’ and ‘Our’ method have been compared on an Intel Core i7-7700HQ with 15,6 GiB RAM. The average covariance generation time over 107 submaps of size mean = 6552.75, std_dev = 766.00 can be seen in Table III, supporting the claim that PointNetKL offers the best trade off between accuracy and processing time to run SLAM online on an AUV.\nVII. CONCLUSIONS\nWe have presented PointNetKL, an ANN designed to learn the uncertainty distribution of the GICP registration process from unordered sets of multidimensional points. In order to train it and test it, we have created a dataset consisting of bathymetric point clouds and their associated registration uncertainties out of underwater surveys, and we have demonstrated how the architecture presented is capable of learning the target distributions. Furthermore, we have established the performance of our model within a SLAM framework in two large missions outside the training set.\nThe results presented indicate that PointNetKL is indeed able to learn the GICP covariances directly from raw point clouds and generalise to unknown environments. This motivates the\n\nTORROBA et al.: PointNetKL: DEEP INFERENCE FOR GICP COVARIANCE ESTIMATION IN BATHYMETRIC SLAM\n\n4085\n\npossibility of using models trained in accessible environments, such as the Baltic, to enhance SLAM in unexplored environments, e.g. Antarctica. Furthermore, the data generation process introduced has proved to work well and alleviate the need for a dataset with sequences of overlapping point clouds with ground truth positioning associated, which are scarce in the underwater domain. Further testing of the network on new graph-SLAM optimisations is required to fully characterise its performance and limitations, but the results presented support our thesis that PointNetKL can be successfully applied in online SLAM with AUVs.\nThe future extension of this work to the 3D domain will focus on estimating the heading of the AUV together with its [x, y] state. Our intuition on this is that the same features in the submaps that anchor the registration in [x, y] would lead the process if the GICP was unconstrained in the yaw as well. This means that the features extracted by PointNetKL should, in general, perform well in 3D.\nACKNOWLEDGEMENT\nThe authors thank MMT for the data used in this work and the Knut and Alice Wallenberg foundation for funding MUST, Mobile Underwater System Tools, project that provided the Hugin AUV for these tests.\nThis work was supported by Stiftelsen för Strategisk Forskning (SSF) through the Swedish Maritime Robotics Centre (SMaRC) (IRC15-0046).\nREFERENCES\n[1] D. Landry, F. Pomerleau, and P. Giguère, “Cello-3d: Estimating the covariance of ICP in the real world,” in Proc. Int. Conf. Robot. Autom., 2019, pp. 8190–8196.\n[2] C. R Qi, H. Su, K. Mo, and L. J Guibas, “Pointnet: Deep learning on point sets for 3d classiﬁcation and segmentation,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit., 2017, pp. 652–660.\n[3] W. Hess, D. Kohler, H. Rapp, and D. Andor, “Real-time loop closure in 2d lidar slam,” in Proc. IEEE Int. Conf. Robot. Autom., 2016, pp. 1271–1278.\n[4] P. V Teixeira, M. Kaess, F. S Hover, and J. J Leonard, “Underwater inspection using sonar-based volumetric submaps,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 2016, pp. 4288–4295.\n[5] P. J Besl and N. D McKay, “Method for registration of 3-d shapes,” in Proc. Sensor fusion IV: Control Paradigms Data Structures, 1992, vol. 1611, pp. 586–606.\n[6] I. Torroba, N. Bore, and J. Folkesson, “A comparison of submap registration methods for multibeam bathymetric mapping,” in Proc. IEEE/OES Auton. Underwater Vehicle Workshop, 2018, pp. 1–6.\n[7] A. Segal, D. Haehnel, and S. Thrun, “Generalized-ICP,” in Proc. Robot.: Sci. Syst. V, University of Washington, Seattle, USA: The MIT Press, vol. 2, Jun. 2009, doi: 10.15607/RSS.2009.V.021.\n[8] A. Censi., “An accurate closed-form estimate of icp’s covariance,” in Proc. IEEE Int. Conf. Robot. Autom., 2007, pp. 3167–3172.\n\n[9] S. M. Prakhya, L. Bingbing, Y. Rui, and W. Lin, “A closed-form estimate of 3d icp covariance,” in Proc. 14th IAPR Int. Conf. Mach. Vision Appl., 2015, pp. 526–529.\n[10] M. Barczyk and S. Bonnabel, “Towards realistic covariance estimation of icp-based kinect v1 scan matching: The 1d case,” in Proc. Amer. Control Conf., 2017, pp. 4833–4838.\n[11] A. G. Buch, D. Kraft, et al, “Prediction of icp pose uncertainties using monte carlo simulation with synthetic depth images,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 2017, pp. 4640–4647.\n[12] A. Tallavajhula, B. Póczos, and A. Kelly, “Nonparametric distribution regression applied to sensor modeling,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 2016, pp. 619–625.\n[13] V. Peretroukhin, L. Clement, M. Giamou, and J. Kelly, “Probe: Predictive robust estimation for visual-inertial navigation,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 2015, pp. 3668–3675.\n[14] M. Savva et al., “Large-scale 3d shape retrieval from shapenet core55: Shrec’17 track,” in Proc. Workshop 3D Object Retrieval, 2017, pp. 39–50.\n[15] C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, and L. J. Guibas, “Volumetric and multi-view cnns for object classiﬁcation on 3D data,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit., 2016, pp. 5648–5656.\n[16] K. Liu, K. Ok, W. Vega-Brown, and N. Roy, “Deep inference for covariance estimation: Learning gaussian noise models for state estimation,” in Proc. IEEE Int. Conf. Robot. Autom., 2018, pp. 1436–1443.\n[17] Y. Zhou and O. Tuzel, “Voxelnet: End-to-end learning for point cloud based 3d object detection,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit., 2018, pp. 4490–4499.\n[18] Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M Solomon, “Dynamic graph cnn for learning on point clouds,” ACM Trans. Graph. (TOG), New York, NY, USA: ACM, vol. 38, no. 5, pp. 1–12, 2019.\n[19] Y. Aoki, H. Goforth, R. Arun Srivatsan, and S. Lucey, “Pointnetlk: Robust & efﬁcient point cloud registration using pointnet,” in Proc. IEEE Conf. Comput. Vision Pattern Recognit., 2019, pp. 7163–7172.\n[20] T. Zheng, C. Changyou, Y. Junsong, L. Bo, and R. Kui et al., “Pointcloud saliency maps,” in Proc. IEEE Int. Conf. Computer Vision, 2019, pp. 1598– 1606.\n[21] I. Torroba, N. Bore, and J. Folkesson, “Towards autonomous industrialscale bathymetric surveying,” in Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., 2019, pp. 6377–6382.\n[22] T. D. Barfoot and P. T. Furgale, “Associating uncertainty with threedimensional poses for use in estimation problems,” IEEE Trans. Robot., vol. 30, no. 3, pp. 679–693, Jun. 2014.\n[23] L. Zhou, X. Cheng, and Y. Zhu, “Terrain aided navigation for autonomous underwater vehicles with coarse maps,” Meas. Sci. Technol., vol. 27, no. 9, 2016, Art. no. 095002.\n[24] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,” in Proc. 3rd Int. Conf. Learn. Representations, San Diego, CA, USA, May 2015. [Online]. Available: http://arxiv.org/abs/1412.6980\n[25] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, “Dropout: A simple way to prevent neural networks from overﬁtting,” J. Mach. Learn. Res., vol. 15, no. 1, pp. 1929–1958, 2014.\n[26] I. Loshchilov and F. Hutter, “Decoupled weight decay regularization,” Int. Conf. Learn. Representations, 2019. [Online]. Available: https:// openreview.net/forum?id=Bkg6RiCqY7\n[27] Y. Yao, L. Rosasco, and A. Caponnetto, “On early stopping in gradient descent learning,” Constructive Approximation, vol. 26, no. 2, pp. 289– 315, 2007.\n[28] E. Olson and M. Kaess, “Evaluating the performance of map optimization algorithms,” in Proc. RSS Workshop Good Exp. Methodology Robot., vol. 15, 2009.\n[29] C. Roman and H. Singh, “Consistency based error evaluation for deep sea bathymetric mapping with robotic vehicles,” in Proc. Int. Conf. Robot. Autom., 2006, pp. 3568–3574.\n\n"}
